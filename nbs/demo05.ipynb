{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59a7c446",
   "metadata": {},
   "source": [
    "# Gradient Boosing Tree (GBT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20af4dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import xgboost as xgb\n",
    "except ImportError:\n",
    "    !pip install xgboost\n",
    "    import xgboost as xgb\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca929f6",
   "metadata": {},
   "source": [
    "## 1. GBT Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a72b643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5197, 11) (5197,)\n",
      "(1300, 11) (1300,)\n"
     ]
    }
   ],
   "source": [
    "# Load regression dafatset https://archive.ics.uci.edu/dataset/186/wine+quality\n",
    "dataset = fetch_ucirepo(id=186)\n",
    "X = dataset.data.features\n",
    "y = dataset.data.targets\n",
    "y = y.values.ravel() # flatten to 1D array\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eadb0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGBTRegressor:\n",
    "    def __init__(self,\n",
    "                 n_estimators=100,\n",
    "                 learning_rate=0.1,\n",
    "                 max_depth=3,\n",
    "                 random_state=None,):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        self.initial_pred = None\n",
    "        self.trees = []\n",
    "\n",
    "    def initialize_prediction(self, y):\n",
    "        return np.full(y.shape[0], np.mean(y))\n",
    "\n",
    "    def compute_negative_gradient(self, y_true, y_pred):\n",
    "        \"\"\"Negative gradient of MSE loss.\"\"\"\n",
    "        return y_true - y_pred\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.initial_pred = self.initialize_prediction(y)\n",
    "        y_pred = self.initial_pred.copy()\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            residuals = self.compute_negative_gradient(y, y_pred)\n",
    "            tree = DecisionTreeRegressor(\n",
    "                max_depth=self.max_depth,\n",
    "                random_state=rng.randint(0, 10_000)\n",
    "            )\n",
    "            tree.fit(X, residuals)\n",
    "\n",
    "            update = tree.predict(X)\n",
    "            y_pred += self.learning_rate * update\n",
    "            self.trees.append(tree)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.full(X.shape[0], np.mean(self.initial_pred))\n",
    "        for tree in self.trees:\n",
    "            update = tree.predict(X)\n",
    "            y_pred += self.learning_rate * update\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "119473f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyGBTRegressor MSE: 0.4798\n"
     ]
    }
   ],
   "source": [
    "my_regressor = MyGBTRegressor(n_estimators=50, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "my_regressor.fit(X_train, y_train)\n",
    "y_pred = my_regressor.predict(X_test)\n",
    "\n",
    "my_mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"MyGBTRegressor MSE: {my_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19c45152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn GradientBoostingRegressor MSE: 0.4795\n"
     ]
    }
   ],
   "source": [
    "# Compare with sklearn's GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "sk_regressor = GradientBoostingRegressor(n_estimators=50, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "sk_regressor.fit(X_train, y_train)\n",
    "sk_y_pred = sk_regressor.predict(X_test)\n",
    "sk_regressor_mse = mean_squared_error(y_test, sk_y_pred)\n",
    "print(f\"Sklearn GradientBoostingRegressor MSE: {sk_regressor_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdff1c0",
   "metadata": {},
   "source": [
    "## 2. GBT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGBTClassifier:\n",
    "    def __init__(self,\n",
    "                 n_estimators=100,\n",
    "                 learning_rate=0.1,\n",
    "                 max_depth=3,\n",
    "                 random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "\n",
    "        self.initial_log_odds = None \n",
    "        self.trees = []\n",
    "\n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "    \n",
    "    def initialize_prediction(self, y):\n",
    "        return np.log(np.sum(y) / (y.shape[0] - np.sum(y))) # log-odds of positive class\n",
    "\n",
    "    def compute_negative_gradient(self, y_true, proba_pred):\n",
    "        return y_true - proba_pred\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y = np.asarray(y).astype(float)\n",
    "        self.initial_log_odds = self.initialize_prediction(y)\n",
    "        f_pred = np.full(y.shape[0], self.initial_log_odds)\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "\n",
    "        for m in range(self.n_estimators):\n",
    "            p_pred = self._sigmoid(f_pred)\n",
    "            residuals = self.compute_negative_gradient(y, p_pred)\n",
    "\n",
    "            tree = DecisionTreeRegressor(\n",
    "                max_depth=self.max_depth,\n",
    "                random_state=rng.randint(0, 10_000)\n",
    "            )\n",
    "            tree.fit(X, residuals)\n",
    "\n",
    "            # Update log-odds: f_{m+1} = f_m + eta * h_m(x)\n",
    "            update = tree.predict(X)\n",
    "            f_pred += self.learning_rate * update\n",
    "\n",
    "            self.trees.append(tree)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _raw_score(self, X):\n",
    "        f_pred = np.full(X.shape[0], self.initial_log_odds)\n",
    "        for tree in self.trees:\n",
    "            f_pred += self.learning_rate * tree.predict(X)\n",
    "        return f_pred\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        f_pred = self._raw_score(X)\n",
    "        p1 = self._sigmoid(f_pred)\n",
    "        p0 = 1.0 - p1\n",
    "        return np.vstack([p0, p1]).T\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return (proba[:, 1] >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9f8054b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (455,)\n",
      "(114, 30) (114,)\n",
      "Unique classes in y: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Load classification dataset https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic\n",
    "dataset = fetch_ucirepo(id=17)\n",
    "X = dataset.data.features\n",
    "y = dataset.data.targets\n",
    "y = y.values.ravel() # flatten to 1D array\n",
    "y = (y == 'M').astype(int)  # Convert labels to 0 and 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(f\"Unique classes in y: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b2c9e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyGBTClassifier Accuracy: 0.9561\n",
      "MyGBTClassifier F1 Score: 0.9412\n",
      "MyGBTClassifier ROC AUC: 0.9671\n"
     ]
    }
   ],
   "source": [
    "my_clf = MyGBTClassifier(n_estimators=50, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "my_clf.fit(X_train, y_train)\n",
    "y_pred = my_clf.predict(X_test)\n",
    "y_pred_proba = my_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"MyGBTClassifier Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"MyGBTClassifier F1 Score: {f1:.4f}\")\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"MyGBTClassifier ROC AUC: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21dc2d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn GradientBoostingClassifier Accuracy: 0.9561\n",
      "Sklearn GradientBoostingClassifier F1 Score: 0.9412\n",
      "Sklearn GradientBoostingClassifier ROC AUC: 0.9957\n"
     ]
    }
   ],
   "source": [
    "# Compare with sklearn's GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "sk_clf = GradientBoostingClassifier(n_estimators=50, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "sk_clf.fit(X_train, y_train)\n",
    "sk_y_pred = sk_clf.predict(X_test)\n",
    "sk_y_pred_proba = sk_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "sk_clf_accuracy = accuracy_score(y_test, sk_y_pred)\n",
    "print(f\"Sklearn GradientBoostingClassifier Accuracy: {sk_clf_accuracy:.4f}\")\n",
    "\n",
    "sk_clf_f1 = f1_score(y_test, sk_y_pred)\n",
    "print(f\"Sklearn GradientBoostingClassifier F1 Score: {sk_clf_f1:.4f}\")\n",
    "\n",
    "sk_clf_roc_auc = roc_auc_score(y_test, sk_y_pred_proba)\n",
    "print(f\"Sklearn GradientBoostingClassifier ROC AUC: {sk_clf_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6414c57b",
   "metadata": {},
   "source": [
    "## 3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdf816c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5197, 11) (5197,)\n",
      "(1300, 11) (1300,)\n"
     ]
    }
   ],
   "source": [
    "# Load regression dafatset https://archive.ics.uci.edu/dataset/186/wine+quality\n",
    "dataset = fetch_ucirepo(id=186)\n",
    "X = dataset.data.features\n",
    "y = dataset.data.targets\n",
    "y = y.values.ravel() # flatten to 1D array\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c5e30e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regressor MSE: 0.4790\n"
     ]
    }
   ],
   "source": [
    "xgb_regressor = xgb.XGBRegressor(\n",
    "    n_estimators=50,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "xgb_regressor.fit(X_train, y_train)\n",
    "y_pred = xgb_regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"XGBoost Regressor MSE: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66833c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (455,)\n",
      "(114, 30) (114,)\n",
      "Unique classes in y: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Load classification dataset https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic\n",
    "dataset = fetch_ucirepo(id=17)\n",
    "X = dataset.data.features\n",
    "y = dataset.data.targets\n",
    "y = y.values.ravel() # flatten to 1D array\n",
    "y = (y == 'M').astype(int)  # Convert labels to 0 and 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(f\"Unique classes in y: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88b1b0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Accuracy: 0.9561\n",
      "XGBoost Classifier ROC AUC: 0.9510\n",
      "XGBoost Classifier F1 Score: 0.9412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khueluu/Documents/Projects/NSU_ML/venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:29:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(\n",
    "    n_estimators=50,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"XGBoost Classifier Accuracy: {accuracy:.4f}\")\n",
    "print(f\"XGBoost Classifier ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"XGBoost Classifier F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dab77c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
