{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c947e1e9",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3186db7c",
   "metadata": {},
   "source": [
    "Write a class `MySVM` for a binary classification task and compare the prediction with `sklearn` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95c339d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ea1d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cvxopt import matrix, solvers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_wine\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aeecc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load classification dataset https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic\n",
    "# dataset = fetch_ucirepo(id=17)\n",
    "# X = dataset.data.features\n",
    "# y = dataset.data.targets\n",
    "# y = y.values.ravel() # flatten to 1D array\n",
    "# y = (y == 'M').astype(int)  # Convert labels to 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21e1538e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((178, 4), (178,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = load_wine(return_X_y=True)[0][:200, :4]\n",
    "y = load_wine(return_X_y=True)[1][:200]\n",
    "y = np.where(y == 0, -1, 1)  # Convert to -1 and 1 labels\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce3f5587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((142, 4), (142,), (36, 4), (36,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ee16d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(X, Y):\n",
    "    \"\"\"Linear kernel: K(x_i, x_j) = x_i^T x_j\"\"\"\n",
    "    return X @ Y.T\n",
    "\n",
    "\n",
    "def rbf_kernel(X, Y, gamma=1.0):\n",
    "    \"\"\"RBF kernel.\"\"\"\n",
    "    X_norm = np.sum(X**2, axis=1).reshape(-1, 1)\n",
    "    Y_norm = np.sum(Y**2, axis=1).reshape(1, -1)\n",
    "    sq_dists = X_norm + Y_norm - 2 * (X @ Y.T)\n",
    "    return np.exp(-gamma * sq_dists)\n",
    "\n",
    "\n",
    "def polynomial_kernel(X, Y, degree=3, coef0=1.0):\n",
    "    \"\"\"Polynomial kernel.\"\"\"\n",
    "    return (X @ Y.T + coef0) ** degree\n",
    "\n",
    "\n",
    "class MySVM:\n",
    "    \"\"\"\n",
    "    C-SVM solved via QP (cvxopt).\n",
    "\n",
    "    Dual problem:\n",
    "        max  1^T α - 1/2 α^T (Y K Y) α\n",
    "        s.t. 0 ≤ α_i ≤ C,   ∑ α_i y_i = 0\n",
    "\n",
    "    If C is None, use hard-margin (only α_i ≥ 0).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel=linear_kernel, C=1.0):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "\n",
    "        self.alpha = None\n",
    "        self.b = 0.0\n",
    "        self.support_idx = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.w = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float)\n",
    "\n",
    "        # Ensure labels are -1 and +1\n",
    "        unique = np.unique(y)\n",
    "        if set(unique) == {0, 1}:\n",
    "            y = np.where(y == 0, -1.0, 1.0)\n",
    "        elif set(unique) == {-1, 1}:\n",
    "            y = y.astype(float)\n",
    "        else:\n",
    "            raise ValueError(\"Labels must be binary {0,1} or {-1,1}.\")\n",
    "\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        # Gram matrix\n",
    "        K = self.kernel(X, X)\n",
    "\n",
    "        # Build matrices for cvxopt QP:\n",
    "        #  minimize  (1/2) x^T P x + q^T x\n",
    "        #  s.t.      G x <= h\n",
    "        #            A x = b\n",
    "        #\n",
    "        # Here, x = α.\n",
    "        # P = Y K Y, q = -1\n",
    "        Y = np.diag(y)\n",
    "        P = matrix(Y @ K @ Y, tc='d')\n",
    "        q = matrix(-np.ones(n_samples), tc='d')\n",
    "\n",
    "        # Equality constraint: y^T α = 0\n",
    "        A = matrix(y.reshape(1, -1), tc='d')\n",
    "        b = matrix(0.0, tc='d')\n",
    "\n",
    "        # Inequality constraints:\n",
    "        # hard margin: α >= 0  ->  -I α <= 0\n",
    "        # soft margin: 0 <= α <= C ->\n",
    "        #   [ I] α <= [ C]\n",
    "        #   [-I]     [ 0]\n",
    "        if self.C is None:\n",
    "            # Only α >= 0\n",
    "            G = matrix(-np.eye(n_samples), tc='d')\n",
    "            h = matrix(np.zeros(n_samples), tc='d')\n",
    "        else:\n",
    "            G_top = np.eye(n_samples)\n",
    "            G_bottom = -np.eye(n_samples)\n",
    "            G = np.vstack([G_top, G_bottom])\n",
    "\n",
    "            h_top = np.full(n_samples, self.C)\n",
    "            h_bottom = np.zeros(n_samples)\n",
    "            h = np.hstack([h_top, h_bottom])\n",
    "\n",
    "            G = matrix(G, tc='d')\n",
    "            h = matrix(h, tc='d')\n",
    "\n",
    "        # Turn off cvxopt output if you want it quiet:\n",
    "        solvers.options['show_progress'] = False\n",
    "\n",
    "        solution = solvers.qp(P, q, G, h, A, b)\n",
    "        alpha = np.array(solution['x']).reshape(-1)\n",
    "\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # Support vectors: α_i > 0\n",
    "        sv_mask = alpha > 1e-6\n",
    "        self.support_idx = np.where(sv_mask)[0]\n",
    "\n",
    "        # Compute bias b:\n",
    "        # For any SV i with 0 < α_i < C:\n",
    "        #   y_i (w^T φ(x_i) + b) = 1\n",
    "        # => b = y_i - sum_j α_j y_j K_ji\n",
    "        if self.support_idx.size == 0:\n",
    "            self.b = 0.0\n",
    "        else:\n",
    "            # For numerical stability, use only \"free\" SVs\n",
    "            if self.C is None:\n",
    "                free_sv = self.support_idx\n",
    "            else:\n",
    "                free_sv = [\n",
    "                    i for i in self.support_idx\n",
    "                    if 1e-6 < alpha[i] < self.C - 1e-6\n",
    "                ]\n",
    "                if not free_sv:\n",
    "                    # Fallback: use all SVs\n",
    "                    free_sv = list(self.support_idx)\n",
    "\n",
    "            b_list = []\n",
    "            for i in free_sv:\n",
    "                decision_no_b = np.sum(\n",
    "                    alpha * y * K[:, i]\n",
    "                )\n",
    "                b_list.append(y[i] - decision_no_b)\n",
    "            self.b = float(np.mean(b_list))\n",
    "\n",
    "        # Recover w for linear kernel\n",
    "        if self.kernel is linear_kernel:\n",
    "            self.w = (alpha * y) @ X\n",
    "        else:\n",
    "            self.w = None\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        if self.w is not None:\n",
    "            return X @ self.w + self.b\n",
    "\n",
    "        K_test = self.kernel(X, self.X_train)\n",
    "        return (K_test * (self.alpha * self.y_train)).sum(axis=1) + self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        scores = self.decision_function(X)\n",
    "        return np.where(scores >= 0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acaf4420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support vectors: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141]\n",
      "w: [-2.14910889  0.30120087 -6.50523376  0.88122559]\n",
      "b: 25.744209397007044\n",
      "My model: ACC=0.8889, F1=0.9048, ROC AUC=0.8961\n"
     ]
    }
   ],
   "source": [
    "svm = MySVM(kernel=linear_kernel, C=1e10)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print(\"Support vectors:\", svm.support_idx)\n",
    "print(\"w:\", svm.w)\n",
    "print(\"b:\", svm.b)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f\"My model: ACC={accuracy:.4f}, F1={f1:.4f}, ROC AUC={roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "717e7ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK Learn Support vectors: [ 30  32  44  49  81  82  89   7  54  73  95 119 127 135]\n",
      "SK Learn w: [[-1625003.29431152   588990.77801132 -6482709.32610655   609742.50299072]]\n",
      "SK Learn b: [24681022.8087939]\n",
      "My model: ACC=0.8889, F1=0.9048, ROC AUC=0.8961\n",
      "SK Learn: ACC=0.9167, F1=0.9333, ROC AUC=0.9058\n"
     ]
    }
   ],
   "source": [
    "sk_model = SVC(kernel='linear', C=1e10)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_y_pred = sk_model.predict(X_test)\n",
    "\n",
    "print(\"SK Learn Support vectors:\", sk_model.support_)\n",
    "print(\"SK Learn w:\", sk_model.coef_)\n",
    "print(\"SK Learn b:\", sk_model.intercept_)\n",
    "\n",
    "sk_accuracy = accuracy_score(y_test, sk_y_pred)\n",
    "sk_f1 = f1_score(y_test, sk_y_pred)\n",
    "sk_roc_auc = roc_auc_score(y_test, sk_y_pred)\n",
    "\n",
    "print(f\"My model: ACC={accuracy:.4f}, F1={f1:.4f}, ROC AUC={roc_auc:.4f}\")\n",
    "print(f\"SK Learn: ACC={sk_accuracy:.4f}, F1={sk_f1:.4f}, ROC AUC={sk_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6691d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436144fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
